{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29217, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "u=pd.read_csv(\"repositories.csv\")\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of repositories.csv: (22697, 9)\n",
      "Shape of users.csv: (475, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "repositories = pd.read_csv(\"repositories.csv\")\n",
    "users = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# Print the shapes of both dataframes\n",
    "print(\"Shape of repositories.csv:\", repositories.shape)\n",
    "print(\"Shape of users.csv:\", users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>full_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>stargazers_count</th>\n",
       "      <th>watchers_count</th>\n",
       "      <th>language</th>\n",
       "      <th>has_projects</th>\n",
       "      <th>has_wiki</th>\n",
       "      <th>license_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [login, full_name, created_at, stargazers_count, watchers_count, language, has_projects, has_wiki, license_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = repositories[repositories.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDouble,TheOfficialFloW,Seldaek,riscv,JonnyBurger\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sort by number of followers in descending order and select the top 5\n",
    "top_5_users = users.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Extract the login column and convert to comma-separated string\n",
    "top_5_logins = ','.join(top_5_users['login'].values)\n",
    "\n",
    "print(top_5_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lejoe,uwolfer,matthiask,oscardelben,panterch\n"
     ]
    }
   ],
   "source": [
    "# Sort users by created_at in ascending order and select the top 5\n",
    "earliest_users = users.sort_values(by='created_at', ascending=True).head(5)\n",
    "\n",
    "# Extract the login column and convert it to a comma-separated string\n",
    "earliest_logins = ','.join(earliest_users['login'].values)\n",
    "\n",
    "print(earliest_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit,other,apache-2.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out missing license names from the repositories data\n",
    "repositories_filtered = repositories.dropna(subset=['license_name'])\n",
    "\n",
    "# Count occurrences of each license name and get the top 3 most common\n",
    "top_licenses = (\n",
    "    repositories_filtered['license_name']\n",
    "    .value_counts()\n",
    "    .head(3)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Convert to a comma-separated string for output\n",
    "top_licenses_str = ','.join(top_licenses)\n",
    "\n",
    "print(top_licenses_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE\n"
     ]
    }
   ],
   "source": [
    "# Clean up the company names\n",
    "users['company'] = (\n",
    "    users['company']\n",
    "    .str.strip()  # Trim whitespace\n",
    "    .str.lstrip('@')  # Strip leading '@' symbols\n",
    "    .str.upper()  # Convert to uppercase\n",
    ")\n",
    "\n",
    "# Get the most common company\n",
    "most_common_company = users['company'].value_counts().idxmax()\n",
    "\n",
    "print(most_common_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each programming language\n",
    "most_popular_language = repositories['language'].value_counts().idxmax()\n",
    "\n",
    "print(most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "users['created_at'] = pd.to_datetime(users['created_at'])\n",
    "\n",
    "# Filter users who joined after 2020\n",
    "recent_users = users[users['created_at'] > '2020-01-01']\n",
    "\n",
    "# Get the logins of these recent users\n",
    "recent_user_logins = recent_users['login'].unique()\n",
    "\n",
    "# Filter the repositories DataFrame for these recent users\n",
    "recent_user_repos = repositories[repositories['login'].isin(recent_user_logins)]\n",
    "\n",
    "# Count the occurrences of each programming language\n",
    "language_counts = recent_user_repos['language'].value_counts()\n",
    "\n",
    "# Get the second most popular programming language\n",
    "second_most_popular_language = language_counts.index[1]\n",
    "\n",
    "print(second_most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitBake\n"
     ]
    }
   ],
   "source": [
    "# Group by language and calculate the average number of stars\n",
    "average_stars_per_language = repositories.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Find the language with the highest average number of stars\n",
    "highest_average_stars_language = average_stars_per_language.idxmax()\n",
    "\n",
    "print(highest_average_stars_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riscv, bpasero, Seldaek, egamma, ethz-asl\n"
     ]
    }
   ],
   "source": [
    "# Calculate leader_strength\n",
    "users['leader_strength'] = users['followers'] / (1 + users['following'])\n",
    "\n",
    "# Get the top 5 users by leader_strength\n",
    "top_leader_strength_users = users.nlargest(5, 'leader_strength')['login']\n",
    "\n",
    "# Convert to a comma-separated string\n",
    "top_leader_strength_logins = ', '.join(top_leader_strength_users)\n",
    "\n",
    "print(top_leader_strength_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.066\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between followers and public_repos\n",
    "correlation = users['followers'].corr(users['public_repos'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "X = users[['public_repos']]  # Independent variable\n",
    "y = users['followers']        # Dependent variable\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient) and intercept\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print the slope rounded to 3 decimal places\n",
    "print(f\"{slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded your repositories DataFrame\n",
    "# Calculate correlation\n",
    "correlation = repositories['has_projects'].astype(int).corr(repositories['has_wiki'].astype(int))\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the repositories.csv file\n",
    "df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Step 2: Change boolean values to lowercase strings\n",
    "df['has_projects'] = df['has_projects'].replace({True: 'true', False: 'false'})\n",
    "df['has_wiki'] = df['has_wiki'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('repositories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-836.444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users dataset\n",
    "users = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the average following for hireable users\n",
    "avg_following_hireable = users[users['hireable'] == True]['following'].mean()\n",
    "\n",
    "# Calculate the average following for non-hireable users\n",
    "avg_following_non_hireable = users[users['hireable'] == False]['following'].mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = avg_following_hireable - avg_following_non_hireable\n",
    "\n",
    "# Print the difference rounded to 3 decimal places\n",
    "print(f\"{difference:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated hireable values in users.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 2: Change boolean values from True/False to true/false (as strings)\n",
    "users_df['hireable'] = users_df['hireable'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the updated DataFrame back to CSV\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "print(\"Updated hireable values in users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter to rows with bios\n",
    "df = df[df['bio'].notna()]\n",
    "\n",
    "# Calculate word count\n",
    "df['word_count'] = df['bio'].str.split().str.len()\n",
    "\n",
    "# Calculate correlation using Pearson method (same as Excel's CORREL)\n",
    "correlation = df['word_count'].corr(df['followers'])\n",
    "\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JonnyBurger, syzer, kynan, nicnocquee, shuhei\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repositories = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert 'created_at' to datetime\n",
    "repositories['created_at'] = pd.to_datetime(repositories['created_at'])\n",
    "\n",
    "# Filter for weekend days (Saturday: 5, Sunday: 6)\n",
    "weekend_repos = repositories[repositories['created_at'].dt.dayofweek >= 5]\n",
    "\n",
    "# Count repositories per user\n",
    "top_users_weekend = weekend_repos['login'].value_counts().head(5)\n",
    "\n",
    "# Get the logins of the top 5 users in order\n",
    "top_users_logins = top_users_weekend.index.tolist()\n",
    "\n",
    "# Print the logins as a comma-separated string\n",
    "print(\", \".join(top_users_logins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repos = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert has_projects and has_wiki to binary (1 for True, 0 for False)\n",
    "repos['projects_enabled'] = repos['has_projects'].astype(int)\n",
    "repos['wiki_enabled'] = repos['has_wiki'].astype(int)\n",
    "\n",
    "# Calculate the correlation between projects enabled and wiki enabled\n",
    "correlation = repos['projects_enabled'].corr(repos['wiki_enabled'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users dataset\n",
    "users = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the fraction of users with email when hireable is True\n",
    "hireable_with_email = users[users['hireable'] == True]['email'].notna().mean()\n",
    "\n",
    "# Calculate the fraction of users with email when hireable is False\n",
    "not_hireable_with_email = users[users['hireable'] == False]['email'].notnull().mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = hireable_with_email - not_hireable_with_email\n",
    "\n",
    "# Print the difference rounded to 3 decimal places\n",
    "print(round(difference, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li, Wang: 4\n"
     ]
    }
   ],
   "source": [
    "users['surname'] = users['name'].dropna().apply(lambda x: x.strip().split()[-1])\n",
    "\n",
    "# Count occurrences of each surname\n",
    "surname_counts = users['surname'].value_counts()\n",
    "\n",
    "# Find the maximum count\n",
    "max_count = surname_counts.max()\n",
    "\n",
    "# Get the most common surnames\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Output the most common surname(s) and the count\n",
    "most_common_surnames_sorted = sorted(most_common_surnames)\n",
    "print(f\"{', '.join(most_common_surnames_sorted)}: {max_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/6p_pd3gd44zfw3nn6n10_pnh0000gn/T/ipykernel_12817/3306240870.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['bio_word_count'] = df_filtered['bio'].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "df = users.copy()\n",
    "\n",
    "# Filter out rows with no bio\n",
    "df_filtered = df.dropna(subset=['bio'])\n",
    "\n",
    "# Split the bio into words and count the number of words\n",
    "df_filtered['bio_word_count'] = df_filtered['bio'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate the correlation between bio word count and followers\n",
    "correlation = df_filtered['bio_word_count'].corr(df_filtered['followers'])\n",
    "\n",
    "# Print the correlation coefficient with 3 decimal places\n",
    "print(f\"Regression slope of followers on bio word count: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
