{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29189, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "u=pd.read_csv(\"repositories.csv\")\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of repositories.csv: (29189, 9)\n",
      "Shape of users.csv: (474, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "repositories = pd.read_csv(\"repositories.csv\")\n",
    "users = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# Print the shapes of both dataframes\n",
    "print(\"Shape of repositories.csv:\", repositories.shape)\n",
    "print(\"Shape of users.csv:\", users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDouble,TheOfficialFloW,Seldaek,riscv,JonnyBurger\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sort by number of followers in descending order and select the top 5\n",
    "top_5_users = users.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Extract the login column and convert to comma-separated string\n",
    "top_5_logins = ','.join(top_5_users['login'].values)\n",
    "\n",
    "print(top_5_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lejoe,uwolfer,matthiask,oscardelben,panterch\n"
     ]
    }
   ],
   "source": [
    "# Sort users by created_at in ascending order and select the top 5\n",
    "earliest_users = users.sort_values(by='created_at', ascending=True).head(5)\n",
    "\n",
    "# Extract the login column and convert it to a comma-separated string\n",
    "earliest_logins = ','.join(earliest_users['login'].values)\n",
    "\n",
    "print(earliest_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit,other,apache-2.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out missing license names from the repositories data\n",
    "repositories_filtered = repositories.dropna(subset=['license_name'])\n",
    "\n",
    "# Count occurrences of each license name and get the top 3 most common\n",
    "top_licenses = (\n",
    "    repositories_filtered['license_name']\n",
    "    .value_counts()\n",
    "    .head(3)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Convert to a comma-separated string for output\n",
    "top_licenses_str = ','.join(top_licenses)\n",
    "\n",
    "print(top_licenses_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE\n"
     ]
    }
   ],
   "source": [
    "# Clean up the company names\n",
    "users['company'] = (\n",
    "    users['company']\n",
    "    .str.strip()  # Trim whitespace\n",
    "    .str.lstrip('@')  # Strip leading '@' symbols\n",
    "    .str.upper()  # Convert to uppercase\n",
    ")\n",
    "\n",
    "# Get the most common company\n",
    "most_common_company = users['company'].value_counts().idxmax()\n",
    "\n",
    "print(most_common_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each programming language\n",
    "most_popular_language = repositories['language'].value_counts().idxmax()\n",
    "\n",
    "print(most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "users['created_at'] = pd.to_datetime(users['created_at'])\n",
    "\n",
    "# Filter users who joined after 2020\n",
    "recent_users = users[users['created_at'] > '2020-01-01']\n",
    "\n",
    "# Get the logins of these recent users\n",
    "recent_user_logins = recent_users['login'].unique()\n",
    "\n",
    "# Filter the repositories DataFrame for these recent users\n",
    "recent_user_repos = repositories[repositories['login'].isin(recent_user_logins)]\n",
    "\n",
    "# Count the occurrences of each programming language\n",
    "language_counts = recent_user_repos['language'].value_counts()\n",
    "\n",
    "# Get the second most popular programming language\n",
    "second_most_popular_language = language_counts.index[1]\n",
    "\n",
    "print(second_most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitBake\n"
     ]
    }
   ],
   "source": [
    "# Group by language and calculate the average number of stars\n",
    "average_stars_per_language = repositories.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Find the language with the highest average number of stars\n",
    "highest_average_stars_language = average_stars_per_language.idxmax()\n",
    "\n",
    "print(highest_average_stars_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riscv, bpasero, Seldaek, egamma, ethz-asl\n"
     ]
    }
   ],
   "source": [
    "# Calculate leader_strength\n",
    "users['leader_strength'] = users['followers'] / (1 + users['following'])\n",
    "\n",
    "# Get the top 5 users by leader_strength\n",
    "top_leader_strength_users = users.nlargest(5, 'leader_strength')['login']\n",
    "\n",
    "# Convert to a comma-separated string\n",
    "top_leader_strength_logins = ', '.join(top_leader_strength_users)\n",
    "\n",
    "print(top_leader_strength_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.066\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between followers and public_repos\n",
    "correlation = users['followers'].corr(users['public_repos'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "X = users[['public_repos']]  # Independent variable\n",
    "y = users['followers']        # Dependent variable\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient) and intercept\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print the slope rounded to 3 decimal places\n",
    "print(f\"{slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded your repositories DataFrame\n",
    "# Calculate correlation\n",
    "correlation = repositories['has_projects'].astype(int).corr(repositories['has_wiki'].astype(int))\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the repositories.csv file\n",
    "df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Step 2: Change boolean values to lowercase strings\n",
    "df['has_projects'] = df['has_projects'].replace({True: 'true', False: 'false'})\n",
    "df['has_wiki'] = df['has_wiki'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('repositories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-836.444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded your users DataFrame\n",
    "# Calculate average following for hireable users\n",
    "avg_following_hireable = users[users['hireable']].following.mean()\n",
    "\n",
    "# Calculate average following for non-hireable users\n",
    "avg_following_non_hireable = users[~users['hireable']].following.mean()\n",
    "\n",
    "# Calculate the difference\n",
    "average_difference = avg_following_hireable - avg_following_non_hireable\n",
    "\n",
    "# Print the result rounded to 3 decimal places\n",
    "print(f\"{average_difference:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated hireable values in users.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 2: Change boolean values from True/False to true/false (as strings)\n",
    "users_df['hireable'] = users_df['hireable'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the updated DataFrame back to CSV\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "print(\"Updated hireable values in users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/6p_pd3gd44zfw3nn6n10_pnh0000gn/T/ipykernel_12817/873808032.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already loaded your users DataFrame\n",
    "# Filter out users without bios\n",
    "users_with_bios = users[users['bio'].notnull()]\n",
    "\n",
    "# Calculate bio word count\n",
    "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n",
    "\n",
    "# Prepare the data for regression\n",
    "X = users_with_bios[['bio_word_count']]\n",
    "y = users_with_bios['followers']\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient) of the regression line\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# Print the result rounded to 3 decimal places\n",
    "print(f\"{slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JonnyBurger, syzer, kynan, nicnocquee, shuhei\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repositories = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert 'created_at' to datetime\n",
    "repositories['created_at'] = pd.to_datetime(repositories['created_at'])\n",
    "\n",
    "# Filter for weekend days (Saturday: 5, Sunday: 6)\n",
    "weekend_repos = repositories[repositories['created_at'].dt.dayofweek >= 5]\n",
    "\n",
    "# Count repositories per user\n",
    "top_users_weekend = weekend_repos['login'].value_counts().head(5)\n",
    "\n",
    "# Get the logins of the top 5 users in order\n",
    "top_users_logins = top_users_weekend.index.tolist()\n",
    "\n",
    "# Print the logins as a comma-separated string\n",
    "print(\", \".join(top_users_logins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repositories = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Calculate the correlation between has_projects and has_wiki\n",
    "correlation = repositories['has_projects'].corr(repositories['has_wiki'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(round(correlation, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
