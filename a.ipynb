{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22697, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "u=pd.read_csv(\"repositories.csv\")\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the repositories.csv file\n",
    "df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Step 2: Change boolean values to lowercase strings\n",
    "df['has_projects'] = df['has_projects'].replace({True: 'true', False: 'false'})\n",
    "df['has_wiki'] = df['has_wiki'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('repositories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the users.csv file\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 2: Change boolean values to lowercase strings\n",
    "df['hireable'] = df['hireable'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "\n",
    "# Step 3: Save the modified DataFrame back to a new CSV file\n",
    "df.to_csv('users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of repositories.csv: (22697, 9)\n",
      "Shape of users.csv: (475, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "repositories = pd.read_csv(\"repositories.csv\")\n",
    "users = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# Print the shapes of both dataframes\n",
    "print(\"Shape of repositories.csv:\", repositories.shape)\n",
    "print(\"Shape of users.csv:\", users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>full_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>stargazers_count</th>\n",
       "      <th>watchers_count</th>\n",
       "      <th>language</th>\n",
       "      <th>has_projects</th>\n",
       "      <th>has_wiki</th>\n",
       "      <th>license_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [login, full_name, created_at, stargazers_count, watchers_count, language, has_projects, has_wiki, license_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = repositories[repositories.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDouble,TheOfficialFloW,Seldaek,riscv,JonnyBurger\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sort by number of followers in descending order and select the top 5\n",
    "top_5_users = users.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Extract the login column and convert to comma-separated string\n",
    "top_5_logins = ','.join(top_5_users['login'].values)\n",
    "\n",
    "print(top_5_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lejoe,uwolfer,matthiask,oscardelben,panterch\n"
     ]
    }
   ],
   "source": [
    "# Sort users by created_at in ascending order and select the top 5\n",
    "earliest_users = users.sort_values(by='created_at', ascending=True).head(5)\n",
    "\n",
    "# Extract the login column and convert it to a comma-separated string\n",
    "earliest_logins = ','.join(earliest_users['login'].values)\n",
    "\n",
    "print(earliest_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit,other,apache-2.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out missing license names from the repositories data\n",
    "repositories_filtered = repositories.dropna(subset=['license_name'])\n",
    "\n",
    "# Count occurrences of each license name and get the top 3 most common\n",
    "top_licenses = (\n",
    "    repositories_filtered['license_name']\n",
    "    .value_counts()\n",
    "    .head(3)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Convert to a comma-separated string for output\n",
    "top_licenses_str = ','.join(top_licenses)\n",
    "\n",
    "print(top_licenses_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE\n"
     ]
    }
   ],
   "source": [
    "# Clean up the company names\n",
    "users['company'] = (\n",
    "    users['company']\n",
    "    .str.strip()  # Trim whitespace\n",
    "    .str.lstrip('@')  # Strip leading '@' symbols\n",
    "    .str.upper()  # Convert to uppercase\n",
    ")\n",
    "\n",
    "# Get the most common company\n",
    "most_common_company = users['company'].value_counts().idxmax()\n",
    "\n",
    "print(most_common_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each programming language\n",
    "most_popular_language = repositories['language'].value_counts().idxmax()\n",
    "\n",
    "print(most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "users['created_at'] = pd.to_datetime(users['created_at'])\n",
    "\n",
    "# Filter users who joined after 2020\n",
    "recent_users = users[users['created_at'] > '2020-01-01']\n",
    "\n",
    "# Get the logins of these recent users\n",
    "recent_user_logins = recent_users['login'].unique()\n",
    "\n",
    "# Filter the repositories DataFrame for these recent users\n",
    "recent_user_repos = repositories[repositories['login'].isin(recent_user_logins)]\n",
    "\n",
    "# Count the occurrences of each programming language\n",
    "language_counts = recent_user_repos['language'].value_counts()\n",
    "\n",
    "# Get the second most popular programming language\n",
    "second_most_popular_language = language_counts.index[1]\n",
    "\n",
    "print(second_most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitBake\n"
     ]
    }
   ],
   "source": [
    "# Group by language and calculate the average number of stars\n",
    "average_stars_per_language = repositories.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Find the language with the highest average number of stars\n",
    "highest_average_stars_language = average_stars_per_language.idxmax()\n",
    "\n",
    "print(highest_average_stars_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riscv, bpasero, Seldaek, egamma, ethz-asl\n"
     ]
    }
   ],
   "source": [
    "# Calculate leader_strength\n",
    "users['leader_strength'] = users['followers'] / (1 + users['following'])\n",
    "\n",
    "# Get the top 5 users by leader_strength\n",
    "top_leader_strength_users = users.nlargest(5, 'leader_strength')['login']\n",
    "\n",
    "# Convert to a comma-separated string\n",
    "top_leader_strength_logins = ', '.join(top_leader_strength_users)\n",
    "\n",
    "print(top_leader_strength_logins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.066\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between followers and public_repos\n",
    "correlation = users['followers'].corr(users['public_repos'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.473\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "X = users[['public_repos']]  # Independent variable\n",
    "y = users['followers']        # Dependent variable\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient) and intercept\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print the slope rounded to 3 decimal places\n",
    "print(f\"{slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded your repositories DataFrame\n",
    "# Calculate correlation\n",
    "correlation = repositories['has_projects'].astype(int).corr(repositories['has_wiki'].astype(int))\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-834.073\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users dataset\n",
    "users = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the average following for hireable users\n",
    "avg_following_hireable = users[users['hireable'] == True]['following'].mean()\n",
    "\n",
    "# Calculate the average following for non-hireable users\n",
    "avg_following_non_hireable = users[users['hireable'] != True]['following'].mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = avg_following_hireable - avg_following_non_hireable\n",
    "\n",
    "# Print the difference rounded to 3 decimal places\n",
    "print(f\"{difference:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated hireable values in users.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 2: Change boolean values from True/False to true/false (as strings)\n",
    "users_df['hireable'] = users_df['hireable'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Step 3: Save the updated DataFrame back to CSV\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "print(\"Updated hireable values in users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter to rows with bios\n",
    "df = df[df['bio'].notna()]\n",
    "\n",
    "# Calculate word count\n",
    "df['word_count'] = df['bio'].str.split().str.len()\n",
    "\n",
    "# Calculate correlation using Pearson method (same as Excel's CORREL)\n",
    "correlation = df['word_count'].corr(df['followers'])\n",
    "\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kynan, yati-sagade, dw5, nicnocquee, sspreitzer\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repositories = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert 'created_at' to datetime\n",
    "repositories['created_at'] = pd.to_datetime(repositories['created_at'])\n",
    "\n",
    "# Filter for weekend days (Saturday: 5, Sunday: 6)\n",
    "weekend_repos = repositories[repositories['created_at'].dt.dayofweek >= 5]\n",
    "\n",
    "# Count repositories per user\n",
    "top_users_weekend = weekend_repos['login'].value_counts().head(5)\n",
    "\n",
    "# Get the logins of the top 5 users in order\n",
    "top_users_logins = top_users_weekend.index.tolist()\n",
    "\n",
    "# Print the logins as a comma-separated string\n",
    "print(\", \".join(top_users_logins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the repositories dataset\n",
    "repos = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert has_projects and has_wiki to binary (1 for True, 0 for False)\n",
    "repos['projects_enabled'] = repos['has_projects'].astype(int)\n",
    "repos['wiki_enabled'] = repos['has_wiki'].astype(int)\n",
    "\n",
    "# Calculate the correlation between projects enabled and wiki enabled\n",
    "correlation = repos['projects_enabled'].corr(repos['wiki_enabled'])\n",
    "\n",
    "# Print the correlation rounded to 3 decimal places\n",
    "print(f\"{correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the users dataset\n",
    "users = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the fraction of users with email when hireable is True\n",
    "hireable_with_email = users[users['hireable'] == True]['email'].notna().mean()\n",
    "\n",
    "# Calculate the fraction of users with email when hireable is False\n",
    "not_hireable_with_email = users[users['hireable'] != True]['email'].notnull().mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = hireable_with_email - not_hireable_with_email\n",
    "\n",
    "# Print the difference rounded to 3 decimal places\n",
    "print(round(difference, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li, Wang: 4\n"
     ]
    }
   ],
   "source": [
    "users['surname'] = users['name'].dropna().apply(lambda x: x.strip().split()[-1])\n",
    "\n",
    "# Count occurrences of each surname\n",
    "surname_counts = users['surname'].value_counts()\n",
    "\n",
    "# Find the maximum count\n",
    "max_count = surname_counts.max()\n",
    "\n",
    "# Get the most common surnames\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Output the most common surname(s) and the count\n",
    "most_common_surnames_sorted = sorted(most_common_surnames)\n",
    "print(f\"{', '.join(most_common_surnames_sorted)}: {max_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/6p_pd3gd44zfw3nn6n10_pnh0000gn/T/ipykernel_6361/3306240870.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['bio_word_count'] = df_filtered['bio'].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "df = users.copy()\n",
    "\n",
    "# Filter out rows with no bio\n",
    "df_filtered = df.dropna(subset=['bio'])\n",
    "\n",
    "# Split the bio into words and count the number of words\n",
    "df_filtered['bio_word_count'] = df_filtered['bio'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate the correlation between bio word count and followers\n",
    "correlation = df_filtered['bio_word_count'].corr(df_filtered['followers'])\n",
    "\n",
    "# Print the correlation coefficient with 3 decimal places\n",
    "print(f\"Regression slope of followers on bio word count: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from statsmodels) (2.0.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/deep_learning/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Overview:\n",
      "             login            name           company  \\\n",
      "0          IDouble        Alp ₿📈🚀🌕  IDEX/USD @IDEXIO   \n",
      "1  TheOfficialFloW     Andy Nguyen               NaN   \n",
      "2          Seldaek  Jordi Boggiano         PACKAGIST   \n",
      "3            riscv          RISC-V               NaN   \n",
      "4      JonnyBurger    Jonny Burger      REMOTION-DEV   \n",
      "\n",
      "                      location                          email hireable  \\\n",
      "0          Zurich, Switzerland                            NaN      NaN   \n",
      "1                       Zurich  theofficialflow1996@gmail.com      NaN   \n",
      "2  Zürich, Zurich, Switzerland             j.boggiano@seld.be      NaN   \n",
      "3                   Zurich, CH                 info@riscv.org      NaN   \n",
      "4          Zurich, Switzerland                    hi@jonny.io      NaN   \n",
      "\n",
      "                                                 bio  public_repos  followers  \\\n",
      "0  🗽 Be greedy when others are fearful and be fea...            61      32862   \n",
      "1                      Information Security Engineer            39       4598   \n",
      "2  \\r\\n    Working on https://packagist.com and h...           259       4562   \n",
      "3     The Open-Standard Instruction Set Architecture            58       3185   \n",
      "4                 Creative hacker @remotion-dev \\r\\n           238       2462   \n",
      "\n",
      "   following            created_at  \n",
      "0     320051  2016-03-31T09:16:13Z  \n",
      "1         32  2015-09-12T08:16:45Z  \n",
      "2          1  2010-01-16T18:28:47Z  \n",
      "3          0  2015-02-05T21:49:09Z  \n",
      "4         30  2012-04-10T14:57:36Z  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 475 entries, 0 to 474\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   login         475 non-null    object\n",
      " 1   name          468 non-null    object\n",
      " 2   company       328 non-null    object\n",
      " 3   location      475 non-null    object\n",
      " 4   email         229 non-null    object\n",
      " 5   hireable      103 non-null    object\n",
      " 6   bio           317 non-null    object\n",
      " 7   public_repos  475 non-null    int64 \n",
      " 8   followers     475 non-null    int64 \n",
      " 9   following     475 non-null    int64 \n",
      " 10  created_at    475 non-null    object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 40.9+ KB\n",
      "None\n",
      "\n",
      "Regression slope of followers on bio word count: 40.505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'users.csv'  # Ensure this path is correct\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Check the first few rows and the data types of the DataFrame\n",
    "print(\"DataFrame Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Filter out users without bios\n",
    "df = df[df['bio'].notnull()]\n",
    "\n",
    "# Calculate the length of each bio in words\n",
    "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
    "\n",
    "# Prepare the independent variable (X) and dependent variable (y)\n",
    "X = df['bio_word_count']\n",
    "y = df['followers']  # Adjust the column name as per your dataset\n",
    "\n",
    "# Add a constant to the independent variable (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the slope (coefficient of the bio_word_count)\n",
    "slope = model.params['bio_word_count']\n",
    "\n",
    "# Print the regression slope rounded to three decimal places\n",
    "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Overview:\n",
      "             login            name           company  \\\n",
      "0          IDouble        Alp ₿📈🚀🌕  IDEX/USD @IDEXIO   \n",
      "1  TheOfficialFloW     Andy Nguyen               NaN   \n",
      "2          Seldaek  Jordi Boggiano         PACKAGIST   \n",
      "3            riscv          RISC-V               NaN   \n",
      "4      JonnyBurger    Jonny Burger      REMOTION-DEV   \n",
      "\n",
      "                      location                          email hireable  \\\n",
      "0          Zurich, Switzerland                            NaN      NaN   \n",
      "1                       Zurich  theofficialflow1996@gmail.com      NaN   \n",
      "2  Zürich, Zurich, Switzerland             j.boggiano@seld.be      NaN   \n",
      "3                   Zurich, CH                 info@riscv.org      NaN   \n",
      "4          Zurich, Switzerland                    hi@jonny.io      NaN   \n",
      "\n",
      "                                                 bio  public_repos  followers  \\\n",
      "0  🗽 Be greedy when others are fearful and be fea...            61      32862   \n",
      "1                      Information Security Engineer            39       4598   \n",
      "2  \\r\\n    Working on https://packagist.com and h...           259       4562   \n",
      "3     The Open-Standard Instruction Set Architecture            58       3185   \n",
      "4                 Creative hacker @remotion-dev \\r\\n           238       2462   \n",
      "\n",
      "   following            created_at  \n",
      "0     320051  2016-03-31T09:16:13Z  \n",
      "1         32  2015-09-12T08:16:45Z  \n",
      "2          1  2010-01-16T18:28:47Z  \n",
      "3          0  2015-02-05T21:49:09Z  \n",
      "4         30  2012-04-10T14:57:36Z  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 475 entries, 0 to 474\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   login         475 non-null    object\n",
      " 1   name          468 non-null    object\n",
      " 2   company       328 non-null    object\n",
      " 3   location      475 non-null    object\n",
      " 4   email         229 non-null    object\n",
      " 5   hireable      103 non-null    object\n",
      " 6   bio           317 non-null    object\n",
      " 7   public_repos  475 non-null    int64 \n",
      " 8   followers     475 non-null    int64 \n",
      " 9   following     475 non-null    int64 \n",
      " 10  created_at    475 non-null    object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 40.9+ KB\n",
      "None\n",
      "\n",
      "Regression slope of followers on bio word count: 40.505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = 'users.csv'  # Ensure this path is correct\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Check the first few rows and the data types of the DataFrame\n",
    "print(\"DataFrame Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Filter out users without bios\n",
    "df = df[df['bio'].notnull()]\n",
    "\n",
    "# Calculate the length of each bio in words\n",
    "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
    "\n",
    "# Prepare the independent variable (X) and dependent variable (y)\n",
    "X = df['bio_word_count']\n",
    "y = df['followers']  # Adjust the column name as per your dataset\n",
    "\n",
    "# Add a constant to the independent variable (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the slope (coefficient of the bio_word_count)\n",
    "slope = model.params['bio_word_count']\n",
    "\n",
    "# Print the regression slope rounded to three decimal places\n",
    "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
